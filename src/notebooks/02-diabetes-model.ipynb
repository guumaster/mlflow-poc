{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Simple Workflow with MLFlow and S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### Set up environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Import all libraries and extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"./extensions\")\n",
    "\n",
    "%load_ext skip_kernel_extension\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "from mlflow import MlflowClient\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Set default values for env variables. These will be overwritten when running inside docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Defaults to be changed when run inside docker\n",
    "os.environ.setdefault(\"AWS_ACCESS_KEY_ID\", \"admin\")\n",
    "os.environ.setdefault(\"AWS_SECRET_ACCESS_KEY\", \"admin123\")\n",
    "os.environ.setdefault(\"MLFLOW_S3_ENDPOINT_URL\", \"http://localhost:9000\")\n",
    "os.environ.setdefault(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "os.environ.setdefault(\"SKIP_INFERENCE\", \"false\")\n",
    "\n",
    "# Set variables\n",
    "aws_access_key_id = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "aws_secret_access_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "mlflow_s3_endpoint_url = os.environ[\"MLFLOW_S3_ENDPOINT_URL\"]\n",
    "mlflow_tracking_uri = os.environ[\"MLFLOW_TRACKING_URI\"]\n",
    "skip_inference = os.environ[\"SKIP_INFERENCE\"].lower() == \"true\"\n",
    "\n",
    "# For inference\n",
    "os.environ.setdefault(\"MODEL_SERVER_URL\", \"http://localhost:7000\")\n",
    "model_server_url = os.environ[\"MODEL_SERVER_URL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "MLflow configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "experiment_name = \"Diabetes Model\"\n",
    "model_name = \"diabetes-model\"\n",
    "\n",
    "mlflow_client = MlflowClient(\n",
    "    tracking_uri=os.getenv(\"MLFLOW_TRACKING_URI\"),\n",
    "    registry_uri=os.getenv(\"MLFLOW_TRACKING_URI\"),\n",
    ")\n",
    "\n",
    "mlflow.set_tracking_uri(uri=os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "experiment = mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "##### Add some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(\n",
    "    client: MlflowClient,\n",
    "    current_run_id: str,\n",
    "    baseline_run_id: str,\n",
    "    metrics_to_compare: dict[str, str],\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare the performance of two runs based on given metrics.\n",
    "\n",
    "    Args:\n",
    "        client (object): Client object to interact with the system.\n",
    "        current_run_id (str): ID of the current run.\n",
    "        baseline_run_id (str): ID of the baseline run.\n",
    "        metrics_to_compare (dict): Dictionary of metrics to compare, where each key is a\n",
    "                                   metric name and its value is a string indicating whether\n",
    "                                   \"higher\" or \"lower\" performance is better.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing boolean values for each metric in `metrics_to_compare`,\n",
    "            indicating whether the current run performed better than the baseline run.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the metrics data from the runs\n",
    "    current_run = client.get_run(current_run_id)\n",
    "    baseline_run = client.get_run(baseline_run_id)\n",
    "\n",
    "    current_metrics = current_run.data.metrics\n",
    "    baseline_metrics = baseline_run.data.metrics\n",
    "\n",
    "    # Initialize a dictionary to store the comparison results\n",
    "    improvement = dict.fromkeys(metrics_to_compare, False)\n",
    "\n",
    "    # Compare each metric\n",
    "    for metric, direction in metrics_to_compare.items():\n",
    "        if direction.lower() == \"higher\":\n",
    "            current_improvement = current_metrics.get(metric) > baseline_metrics.get(metric)\n",
    "        elif direction.lower() == \"lower\":\n",
    "            current_improvement = current_metrics.get(metric) < baseline_metrics.get(metric)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid comparison direction for metric '{metric}'. Use 'higher' or 'lower'.\")\n",
    "\n",
    "        improvement[metric] = current_improvement\n",
    "\n",
    "    return improvement\n",
    "\n",
    "\n",
    "def generate_random_run_name():\n",
    "    \"\"\"\n",
    "    Generates a random (semi) aviation-related name in slug form.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with the name in lowercase, containing an adjective and noun, followed by a 3-digit suffix.\n",
    "\n",
    "    \"\"\"\n",
    "    adjectives = [\n",
    "        \"Transonic\",\n",
    "        \"Hypersonic\",\n",
    "        \"Afterburning\",\n",
    "        \"Turbocharged\",\n",
    "        \"Supersonic\",\n",
    "        \"Machbreaking\",\n",
    "        \"Scramjet\",\n",
    "        \"Thrustvectored\",\n",
    "        \"Stratospheric\",\n",
    "        \"Tropospheric\",\n",
    "        \"Cloudpiercing\",\n",
    "        \"Jetstreamed\",\n",
    "        \"Contrailswept\",\n",
    "        \"Headwinded\",\n",
    "        \"Tailwinded\",\n",
    "        \"Crosswinded\",\n",
    "        \"Flybywire\",\n",
    "        \"Autothrottle\",\n",
    "        \"Glasscockpit\",\n",
    "        \"Headup\",\n",
    "        \"Skybound\",\n",
    "        \"Runwaylit\",\n",
    "        \"Aileronrolled\",\n",
    "        \"Flapsdown\",\n",
    "        \"Chocksaway\",\n",
    "        \"Clearedfortakeoff\",\n",
    "        \"Finalapproach\",\n",
    "        \"Goaround\",\n",
    "        \"Quantum\",\n",
    "        \"Neural\",\n",
    "        \"Plasma\",\n",
    "        \"Gravitic\",\n",
    "        \"Singularity\",\n",
    "        \"Nanotech\",\n",
    "        \"Exo\",\n",
    "        \"Hyperspace\",\n",
    "        \"Photon\",\n",
    "        \"Cloaking\",\n",
    "        \"Tachyon\",\n",
    "        \"Warp\",\n",
    "        \"Zero-G\",\n",
    "        \"Cybernetic\",\n",
    "        \"Holographic\",\n",
    "        \"Ion\",\n",
    "        \"Antimatter\",\n",
    "        \"Bioengineered\",\n",
    "        \"Psi\",\n",
    "        \"Chronojump\",\n",
    "    ]\n",
    "\n",
    "    nouns = [\n",
    "        \"Turbofan\",\n",
    "        \"Tailfin\",\n",
    "        \"Flaps\",\n",
    "        \"Ailerons\",\n",
    "        \"Elevator\",\n",
    "        \"Rudder\",\n",
    "        \"Spoilers\",\n",
    "        \"Slats\",\n",
    "        \"Throttle\",\n",
    "        \"Yawdamper\",\n",
    "        \"Stick\",\n",
    "        \"Pedals\",\n",
    "        \"Tarmac\",\n",
    "        \"Hangar\",\n",
    "        \"Airstrip\",\n",
    "        \"Runway\",\n",
    "        \"Taxiway\",\n",
    "        \"Apron\",\n",
    "        \"Jetbridge\",\n",
    "        \"Windsock\",\n",
    "        \"Glideslope\",\n",
    "        \"Localizer\",\n",
    "        \"Gliderail\",\n",
    "        \"Flightdeck\",\n",
    "        \"Blackbox\",\n",
    "        \"Transponder\",\n",
    "        \"Squawkbox\",\n",
    "        \"Takeoff\",\n",
    "        \"Landing\",\n",
    "        \"Approach\",\n",
    "        \"Holdingpattern\",\n",
    "        \"Jumpgate\",\n",
    "        \"Thruster\",\n",
    "        \"Pulsejet\",\n",
    "        \"Shield\",\n",
    "        \"Wormhole\",\n",
    "        \"Drone\",\n",
    "        \"Neurohelm\",\n",
    "        \"Gravcoil\",\n",
    "        \"Phasewings\",\n",
    "        \"Starfighter\",\n",
    "        \"Titanium\",\n",
    "        \"Voidship\",\n",
    "        \"Lasercannon\",\n",
    "        \"AI\",\n",
    "        \"Stasis\",\n",
    "        \"Dyson\",\n",
    "        \"Warpcore\",\n",
    "        \"Omnitool\",\n",
    "        \"Singularity\",\n",
    "        \"Hoverpad\",\n",
    "    ]\n",
    "\n",
    "    random_adjective = random.choice(adjectives).lower()\n",
    "    random_noun = random.choice(nouns).lower()\n",
    "\n",
    "    # Generate a 3-digit suffix\n",
    "    suffix = str(random.randint(100, 999))\n",
    "\n",
    "    return f\"{random_adjective}-{random_noun}-{suffix}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Load datatest and previous metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_run = None\n",
    "latest_metrics = {\"test_rmse\": None, \"test_mae\": None, \"test_r2\": None}\n",
    "res = []\n",
    "\n",
    "if experiment:\n",
    "    res = mlflow_client.search_runs(experiment.experiment_id, order_by=[\"attributes.start_time DESC\"], max_results=1)\n",
    "    if len(res) > 0:\n",
    "        latest_run = res[0]\n",
    "        latest_metrics = latest_run.data.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Model Training with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter ranges\n",
    "n_estimators_range = (10, 600)\n",
    "max_depth_range = (5, 30)\n",
    "max_features_range = (2, 20)\n",
    "min_samples_leaf_range = (1, 100)\n",
    "\n",
    "max_search_attempts = 5\n",
    "\n",
    "# Create a parent run for all the attempts\n",
    "with mlflow.start_run(run_name=generate_random_run_name()) as parent_run:\n",
    "    # Enable MLflow's automatic experiment tracking for scikit-learn\n",
    "    mlflow.sklearn.autolog(log_models=False)  # Model is logged separately below\n",
    "\n",
    "    print(f\"Starting hyperparameter search under parent run {parent_run.info.run_id}\")\n",
    "    # Record the run ID using scrapbook\n",
    "    sb.glue(\"mlflow_parent_run_id\", parent_run.info.run_id)\n",
    "\n",
    "    best_run = None\n",
    "    improvement_found = False\n",
    "    for attempt in range(1, max_search_attempts + 1):\n",
    "        print(f\"\\n=== Attempt {attempt}/{max_search_attempts} ===\")\n",
    "\n",
    "        # Randomize the hyperparameters\n",
    "        n_estimators = random.randint(*n_estimators_range)\n",
    "        max_depth = random.randint(*max_depth_range)\n",
    "        max_features = random.randint(*max_features_range)\n",
    "        min_samples_leaf = random.randint(*min_samples_leaf_range)\n",
    "        random_seed = random.randint(0, 1000)\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"{parent_run.info.run_name}-attempt-{attempt}\", nested=True) as child_run:\n",
    "            print(f\"Starting nested run {child_run.info.run_id}\")\n",
    "\n",
    "            # Load the training dataset\n",
    "            X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, random_state=random_seed)\n",
    "\n",
    "            mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "            mlflow.log_param(\"max_depth\", max_depth)\n",
    "            mlflow.log_param(\"max_features\", max_features)\n",
    "            mlflow.log_param(\"min_samples_leaf\", min_samples_leaf)\n",
    "\n",
    "            rf = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                max_features=max_features,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                random_state=random_seed,\n",
    "            )\n",
    "\n",
    "            # MLflow triggers logging automatically upon model fitting\n",
    "            rf.fit(X_train, y_train)\n",
    "            # Make predictions\n",
    "            y_pred = rf.predict(X_test)\n",
    "\n",
    "            # Calculate and log regression metrics\n",
    "            current_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            current_mae = mean_absolute_error(y_test, y_pred)\n",
    "            current_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            current_metrics = {\"test_rmse\": current_rmse, \"test_mae\": current_mae, \"test_r2\": current_r2}\n",
    "\n",
    "            mlflow.log_metrics(current_metrics, run_id=child_run.info.run_id)\n",
    "            mlflow.log_metrics(current_metrics, run_id=parent_run.info.run_id, step=attempt)\n",
    "\n",
    "            # Log the model with dependencies and metadata\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=rf,\n",
    "                artifact_path=\"model\",\n",
    "                # registered_model_name=model_name,\n",
    "                extra_pip_requirements=[\"boto3==1.38.16\"],\n",
    "                input_example=X_train[:5],  # Example input for schema inference\n",
    "                signature=mlflow.models.infer_signature(X_train, y_pred),  # Model signature\n",
    "            )\n",
    "\n",
    "            if latest_run is None:\n",
    "                print(\"✅ No previous run found, this will be our baseline\")\n",
    "                best_run = child_run\n",
    "                improvement_found = True\n",
    "                break\n",
    "\n",
    "            # Compare metrics\n",
    "            improvement = compare_metrics(\n",
    "                mlflow_client,\n",
    "                child_run.info.run_id,\n",
    "                latest_run.info.run_id,\n",
    "                {\"test_r2\": \"higher\", \"test_rmse\": \"lower\", \"test_mae\": \"lower\"},\n",
    "            )\n",
    "\n",
    "            # Print improvement status\n",
    "            for metric, result in improvement.items():\n",
    "                print(f\"Improvement on {metric}: {'Yes' if result else 'No'}\")\n",
    "\n",
    "            if all(improvement.values()):\n",
    "                print(\"✅ Found better performing model!\")\n",
    "                best_run = child_run\n",
    "                improvement_found = True\n",
    "                break\n",
    "\n",
    "    # After all attempts (or early exit)\n",
    "    if improvement_found:\n",
    "        print(f\"\\n🎉 Found improved model after {attempt} attempts\")\n",
    "        model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "        model_version = mlflow.register_model(model_uri, model_name)\n",
    "        mlflow_client.set_registered_model_alias(name=model_name, alias=\"dev\", version=model_version.version)\n",
    "        latest_run = best_run\n",
    "        # Record the run ID with the model registered using scrapbook\n",
    "        sb.glue(\"mlflow_model_run_id\", best_run.info.run_id)\n",
    "\n",
    "        print(f\"Model registered as '{model_name}' version {model_version.version}\")\n",
    "    else:\n",
    "        print(f\"\\n🔴 No improvement found after {max_search_attempts} attempts\")\n",
    "        # Close the experiment as failure if no improvements found\n",
    "        mlflow.end_run(\"FAILED\")\n",
    "        if latest_run:\n",
    "            print(\"Keeping the previous best model\")\n",
    "        else:\n",
    "            print(\"No model was registered (no baseline found)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "##### Skip inference cells\n",
    "\n",
    "This checkbox can be marked to skip all subsequent cells during Dagster run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Checkbox\n",
    "\n",
    "skip_inference = Checkbox(\n",
    "    value=os.environ[\"SKIP_INFERENCE\"].lower() == \"true\",\n",
    "    description=\"Skip inference\",\n",
    "    disabled=False,\n",
    "    indent=False,\n",
    ")\n",
    "\n",
    "skip_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "##### Load the model with MLflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $skip_inference.value\n",
    "\n",
    "latest_version_info = mlflow_client.get_model_version_by_alias(model_name, \"dev\")\n",
    "print(f\"Latest model version: {latest_version_info.version}. Alias: {latest_version_info.aliases}\")\n",
    "\n",
    "# model_uri =\"models:/diabetes-model@dev\"\n",
    "model_uri = f\"models:/{model_name}/{latest_version_info.version}\"\n",
    "\n",
    "latest_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "latest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Make predictions for all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $skip_inference.value\n",
    "\n",
    "# Convert diabetes data to a Pandas DataFrame\n",
    "X_test = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "\n",
    "# Make predictions on the diabetes dataset\n",
    "predictions = latest_model.predict(X_test)\n",
    "\n",
    "# Add the predictions to a DataFrame\n",
    "diabetes_result = pd.DataFrame(X_test, columns=dataset.feature_names)\n",
    "# Since we don't have actual classes for the diabetes dataset, we can't add them\n",
    "# diabetes_result[\"actual_class\"] = y_test (commented out as not applicable)\n",
    "diabetes_result_with_predictions = diabetes_result.copy()\n",
    "\n",
    "# Add the model predictions to the DataFrame\n",
    "diabetes_result_with_predictions[\"predicted_value\"] = predictions\n",
    "\n",
    "print(\"Diabetes result shape:\", diabetes_result_with_predictions.shape)\n",
    "\n",
    "diabetes_result_with_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Use model server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Ensure mlserver container is running in docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "[ \"$SKIP_INFERENCE\" = true ] && echo \"SKIP: $SKIP_INFERENCE\" && exit 0\n",
    "\n",
    "export MODEL_VERSION=$(curl -s -X GET \"http://localhost:5000/api/2.0/mlflow/registered-models/alias?name=diabetes-model&alias=dev\" \\\n",
    "    | jq -r '.model_version.version')\n",
    "\n",
    "echo \"Model version: $MODEL_VERSION\"\n",
    "\n",
    "echo \"Restarting docker with latest version\"\n",
    "\n",
    "docker-compose --profile model-server up -d  --force-recreate mlflow-diabetes-model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "##### Make predictions through model server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_diabetes()\n",
    "\n",
    "diabetes_result = pd.DataFrame(dataset[\"data\"], columns=dataset[\"feature_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Make a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $skip_inference.value\n",
    "\n",
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "# select random row\n",
    "row = diabetes_result.sample().iloc[0].to_list()  # Select a random row from the dataset\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{model_server_url}/invocations\",\n",
    "    json={\"dataframe_split\": {\"columns\": diabetes_result.columns.to_list(), \"data\": [row]}},\n",
    "    timeout=5,\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $skip_inference.value\n",
    "\n",
    "# select first/last rows\n",
    "first_last = pd.concat([diabetes_result.iloc[[0]], diabetes_result.iloc[[-1]]])\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{model_server_url}/invocations\",\n",
    "    json={\"dataframe_split\": {\"columns\": diabetes_result.columns.to_list(), \"data\": first_last.values.tolist()}},\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Make prediction for all rows in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $skip_inference.value\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{model_server_url}/invocations\",\n",
    "    json={\"dataframe_split\": {\"columns\": diabetes_result.columns.to_list(), \"data\": diabetes_result.values.tolist()}},\n",
    ")\n",
    "response_data = response.json()\n",
    "# print(json.dumps(response_data, indent=4))\n",
    "\n",
    "diabetes_result_with_predictions = diabetes_result.copy()\n",
    "diabetes_result_with_predictions[\"predictions_response\"] = response_data[\"predictions\"]\n",
    "\n",
    "diabetes_result_with_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Check model server status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $skip_inference.value\n",
    "\n",
    "response = requests.post(f\"{model_server_url}/v2/repository/index\", json={})\n",
    "pretty_json = json.dumps(response.json(), indent=4)\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Force a model reload with latest version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Force a model reload on model server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $skip_inference.value\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{model_server_url}/v2/repository/models/diabetes-model/load\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    timeout=10,\n",
    ")\n",
    "response.raise_for_status()"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "iopub_status": {}
  },
  "jupytext": {
   "cell_metadata_filter": "all,-pycharm",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "all,-pycharm"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
